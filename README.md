# Text-Processing-Pipeline (NLP)
* First, save the links to be scraped in a csv with random URL'id (here input.csv).
* Then scrape the links and save the output text files to a output directory (here output_data).
* The processing script takes in a input directory (output) where text files are saved and a csv of URL_ID's (can be arbitary numbers) and URL's.
* Output_csv: A csv with all the calculated fields and corresponding URL_ID and URL as a row.

Example Output: <br />
| URL_ID  | URL  | Avg Sentence Length | Count of Complex Words | Fog Index |
| -------:|-----:|:-------------------:| ----------------------:| ---------:|
| -------:|-----:|:-------------------:| ----------------------:| ---------:|
| -------:|-----:|:-------------------:| ----------------------:| ---------:|
| -------:|-----:|:-------------------:| ----------------------:| ---------:|
